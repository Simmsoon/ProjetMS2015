% definit le type de document et ses options
\documentclass[a4paper,12pt]{article}

% des paquetages indispensables, qui ajoutent des fonctionnalites
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts, amsmath, amssymb, amstext, latexsym,bm,float}
\usepackage{fullpage}
\usepackage{graphicx, epsifig}
\usepackage{url}
\usepackage{xspace}
\usepackage[francais]{babel}
% pour ecrire les reponses
\newtheorem{exercice}{Exercice}

% des commandes utiles pour ecrire des maths : rajoutez les votres!
\newcommand{\dx}{\,dx}
\newcommand{\ito}{,\dotsc,}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Poly}[1]{\mathcal{P}_{#1}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\pars}[1]{\left(#1\right)}
\newcommand{\bigpars}[1]{\bigl(#1\bigr)}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\ind}{{{\large 1} \hspace*{-1.6mm} {\large 1}}}

% titre, auteur et date
\title{TP Principes et M\'{e}thodes Statistiques}
\author{Gabriel Sarrazin, Nejmeddine Douma, Simon Rabourg}
\date{Avril 2015}

% le debut du contenu
%===============
\begin{document}
%===============

% pour afficher titre, auteur et date
\maketitle

\section{Analyse des défauts de cuves}

\begin{enumerate}

\item Les mesures des trois cuves présentent des valeurs minimums assez proches les unes des autres: 2.007, 2.006 et 2.059 ce qui s'explique par la précision de l'appareil A qui ne détecte que les défauts de taille supèrieure à 2 mm. La cuve 1 s'empare de la valeur maximale 6.416, la variance la plus grande 1.046943 , le maximum des écat-types 1.023202 et du maximum du coefficient de variation empirique 0.3563262. Tandis que la cuve 2 possède le minimum de la valeur médiane 2.362 et de la valeur moyenne 2.592. Les mesures de la cuve 3 présentent le plus de régularité avec le minimum de variation 0.15907528, le minimum d'écart-type 0.4163554 et de coefficient de variation empirique 0.1475989 .

D'après les allures des histogrammes des mesures de la cuve 1 (figures 1 et 2) et celles des mesures de la cuve 2 (figures 3 et 4), ces deux échantillions sont vraisemblablement de loi exponentielle. Les figures 5 et 6 montrent que les mesures de la cuve 3 sont vraisemblalement de loi normale.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histopas_cuve1.pdf}
\caption{Histogramme à pas constant de cuve1 obtenu dans R}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histoeff_cuve1.pdf}
\caption{Histogramme à classe de même effectif de cuve1 obtenu dans R}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histopas_cuve2.pdf}
\caption{Histogramme à pas constant de cuve2 obtenu dans R}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histoeff_cuve2.pdf}
\caption{Histogramme à classe de même effectif de cuve2 obtenu dans R}
\end{figure}

\begin{figure*}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histopas_cuve3.pdf}
\caption{Histogramme à pas constant de cuve3 obtenu dans R}
\end{figure*}

\begin{figure*}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/histoeff_cuve3.pdf}
\caption{Histogramme à classe de même effectif de cuve3 obtenu dans R}
\end{figure*}





\vspace{3mm}


\item Caculons $F_x$, la fonction de répartition de $X$.

$X$ est une variable aléatoire de loi ${\cal P}a(a, 2)$,  sa densité est :
$$ f(x) = \frac{a \, 2^a}{x^{1+a}} \, \ind_{[2,+\infty[}(x)$$

Donc,


 \begin{eqnarray*}
F_x(x) &  = &  \int_{-\infty}^{x} \frac{a \, 2^a}{t^{1+a}} \, \ind_{[2,+\infty[}(t) \, \mathrm dt  \\
 &  = & { \left\{ \begin{array}{l l}  \int_{2}^{x} a  2^a \, t^{-(1+a)} \, \mathrm dt  & si \, x > 2  \\ 0 & sinon. \\\end{array} \right.}   \\
 F_x(x) &  = & { \left\{ \begin{array}{l l}   1 - 2^a \, x^{-a}  & si  x > 2  \\ 0 & sinon. \\\end{array} \right. }  \\
\end{eqnarray*}

\vspace{3mm}

Le théorème de transfert donne:


\begin{eqnarray*}
\bm{ \mathbb{E}}[X] &  = & \int_{-\infty}^{+\infty} t\, \frac{a \, 2^a}{t^{1+a}} \, \ind_{[2,+\infty[}(t) \, \mathrm dt  \\
 & = & a \, 2^a \, \int_{2}^{+\infty}  \frac{1}{t^{a}} \, \mathrm dt  \\
\\
\end{eqnarray*}


Donc,
$${\cal P}a(a, 2) \, \text{admet une espérance finie} \Leftrightarrow a > 1 $$

\vspace{3mm}

\begin{eqnarray*}
Var(X) &  = &  \bm{ \mathbb{E}}[X^2] - \bm{ \mathbb{E}}[X]^2   \\
 & = &  a \, 2^a \, \int_{2}^{+\infty}  \frac{1}{t^{a-1}} \, \mathrm dt  -  (a \, 2^a \, \int_{2}^{+\infty}  \frac{1}{t^{a}} \, \mathrm dt)^2   \\
\\
\end{eqnarray*}


Donc,
$${\cal P}a(a, 2)\,  \text{admet une variance finie} \Leftrightarrow a > 2 $$




\item Caculons $F_Y$, la fonction de répartition de Y=$\ln { \frac{X}{2}}$.

 \begin{eqnarray*}
F_Y(x) &  = &   \bm{ \mathbb{P}}( Y < x )   \\
 &  = & \bm{ \mathbb{P}}(\ln { \frac{X}{2}} < x )   \\
 &  = & \bm{ \mathbb{P}}(\ln X - \ln 2  < x )  \\
 &  = & \bm{ \mathbb{P}}(X  < \exp ( x + \ln 2) )  \\
 &  = & \bm{ \mathbb{P}}(X  < 2\exp(x) )  \\
 &  = &  F_X(2\exp(x)) \\
 &  = &   {\left\{ \begin{array}{l l}   1 - 2^a (2\exp(x))^{-a}  & si \, x > 2  \\ 0 & sinon. \\\end{array} \right.}  \\
F_Y(x)  &  = &   { \left\{ \begin{array}{l l}   1 - \exp(-ax)   & si \, x > 2  \\ 0 & sinon. \\\end{array} \right.}  \\
\\
\end{eqnarray*} 

Donc Y suit la loi $\cal{E}$(a).

\vspace{3mm}

\item Trouvons une fonction pivotale pour déterminer l'expression d'un intervalle de confiance de seuil $\alpha$ pour a.
On a besoin des trois lemmes suivant:


Lemme 1: 
Si $\lambda$>0, $\mu$ >0 et  $X$ une variable aléatoire réelle de loi $\cal{E}$($\lambda$) alors $\mu X \sim  \cal{E}(\frac{\lambda}{\mu}) $

Lemme 2: 
Si $X_1, X_2, ... , X_n$ une famille de variables aléatoires réelles indépendantes et identiquement distriuées de loi  $\cal{E}$($\lambda$) alors $\sum_{i=0}^{n}X_i \sim \Gamma ($n,$\lambda)$.

Lemme 3: 
$\Gamma ($n, $\frac{1}{2}$) et $\chi_{2n}^{2}$ décrivent la même loi de probabilité.

 Soit $Y_1, Y_2, ... , Y_n$ une famille de variables aléatoires réelles indépendantes et identiquement distriuées de loi  $\cal{E}$(a). 
$2aY_1, 2aY_2, ... , 2aY_n$ sont donc de loi $ \cal{E}$($\frac{1}{2}$) (Lemme 1).
D'où, 2a$\sum_{i=0}^{n}Y_i \sim \Gamma ($n,$\frac{1}{2})$ (Lemme 2).
Donc, 2a$\sum_{i=0}^{n}Y_i \sim \chi_{2n}^{2}$.
Or $\chi_{2n}^{2}$ ne dépend pas du paramètre a, donc 2a$\sum_{i=0}^{n}Y_i$ est une fonction pivotale.

En notant $z_{n,\alpha}$ le (1-$\alpha$)-quantile de la loi $\chi_{2n}^{2}$ on a:

$$ \bm{ \mathbb{P}}( z_{2n,1-\frac{\alpha}{2}} \leq   2a\sum_{i=0}^{n}Y_i \leq  z_{2n,\frac{\alpha}{2}} ) = 1 - \frac{\alpha}{2} - \frac{\alpha}{2} = 1-\alpha $$

D'où:

$$ \bm{ \mathbb{P}}(a \in [\frac{z_{2n,1-\frac{\alpha}{2}} }{ 2a\sum_{i=0}^{n}Y_i}, \frac{ z_{2n,\frac{\alpha}{2}}}{ 2a\sum_{i=0}^{n}Y_i}]) = 1-\alpha $$

Donc:

$ [\frac{z_{2n,1-\frac{\alpha}{2}} }{ 2a\sum_{i=0}^{n}Y_i}, \frac{ z_{2n,\frac{\alpha}{2}}}{ 2a\sum_{i=0}^{n}Y_i}] $ est un intervalle de confiance de seuil $\alpha$ pour a.

\vspace{3mm}

\item On a  $F_Y(x) = 1 - \exp(-ax)$, d'où $\ln(1-F_Y(x)) = -ax $. Par conséquent, le graphe de probabilités est le nuage de points $(Y_i,\ln(1-\frac{i}{n})), i \in {1,...,n-1}$.

Le tracé des graphes de probabilités sous {\tt R } (figure 7) des échantillions de la cuve 1 et la cuve 2 permettent de considérer que les points sont approximativement allignés sur une droite de pente négative et passants par l'origine, donc on peut considérer qu'il est vraisemblable que les mesures des faissures des cuves 1 et 2 suivent une loi exponentielle. Le graphe de probabilité des échantillions de la cuve 3 semble plus proche d'un logarithme que d'une droite. On en conclue que la loi exponentielle n'est pas un modèle approprié pour ces données.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP1Q5.pdf}
\caption{Graphes de probabilités}
\end{figure}

On sait que l'estimateur de maximum de vraisemblance et l'estimateur des moments de $\lambda$ pour un échantillion $Y_1, Y_2, ... , Y_n$   qui suit une loi exponentielle de paramètre $\lambda$ sont égaux à $\hat{\lambda_n} = \frac{1}{\bar{Y_n}}$. Ce qui donne les valeurs suivantes de $\hat{a_n}$ pour chacune des trois cuves:

$\hat{a_{cuve1}}$ = 3.170032

$\hat{a_{cuve2}}$ = 4.331652

$\hat{a_{cuve3}}$ = 2.998926

\vspace{3mm}

\item D'après la question 1, les données des cuves 1 et 2 sont vraisemblablement de loi exponentielle et celles de la cuve 3 est vraisemblablement de loi normale. Pour vérifier ces résultats on trace les graphes de probabilités dans {\tt R} 
et on obtient les figures 8 et 9, qui sont en adéquation avec les résultat de la première question.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP1Q6A.pdf}
\caption{Graphes de probabilités des données de cuve 1 et cuve 2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP1Q6B.pdf}
\caption{Graphes de probabilités des données de cuve 3}
\end{figure}




\item
\begin{enumerate}
\item

 Les défauts sont classés dangereux lorsque leur taille est supérieure à 5 mm. Le constructeur assure que ses cuves après 5 années d'utilisation ne présenteront pas une proportion de défauts dangereux supérieure à 5\%. Ce qui équivaut à dire: $\bm{ \mathbb{P}}( X > 5  ) < 0.05$

Or, d'après la question 2, $$\bm{ \mathbb{P}}( X \leq 5  )= 1 - 2^a \, 5^{-a}$$
D'où, $$\bm{ \mathbb{P}}( X > 5  )= 1 -  \bm{\mathbb{P}}( X \leq 5  ) = 2^a \, 5^{-a}$$
Donc, $$\bm{ \mathbb{P}}( X > 5  ) < 0.05 \Leftrightarrow  2^a \, 5^{-a} < 0.05 \Leftrightarrow a > \ln (0.05)/\ln(\frac{2}{5})= 3.269412 $$

D'après les estimations de a trouvées à la question 5, on peut dire que les affirmations du constructeur ne sont valides que pour les données de la cuve 2.

\item 

Sur les 30 mesures faites pour la cuve 1, 2 seulement présentent des mesures supèrieures à 5 mm et seront signaler par l'appareil B. Ce qui fait 6.7\% > 5\% et contredit les affirmations du constructeur. Cette imprécision dans les estimations du constructeur peut être lié à plusieurs facteurs tels que: un mauvais choix de la loi de probabilité, condition extèrieures différentes par rapport aux expèriences du constructeur (température, pression, contenus des cuves, ...)

Avec l'appareil B on obtient des valeurs qui suit une loi binomiale. C'est une loi discrète et on perd donc de l'information sur l'état des défauts. Par exemple savoir les défaults proche de 5 mm peut donner à l'entreprise une idée sur la durée de vie restante de ces cuves et donc savoir qu'il faut penser à les changer bientôt ce qui garantit des meilleures prévisions budgétaires.


\end{enumerate}
\end{enumerate}


\section{V\'{e}rifications exp\'{e}rimentales \`{a} base de simulations}


\begin{enumerate}
\item Il est possible de simuler n \'{e}chantillons de la loi Pa(a,b) car nous connaissons sa fonction de r\'{e}partiton. 
\\
$P_a(a,b)$ est une fonction continue, elle peut donc s'apparenter \`{a} une loi uniforme.  Dans un premier temps, simuler n \'{e}chantillons de cette loi va donc consister  \`{a} tirer, au hasard, n valeurs al\'{e}atoires sur l'intervalle [0,1]. Connaissant la fonction de r\'{e}partition de la loi  $P_a(a,b)$,nous allons ensuite calculer l'image inverse $ F^{-1}(Ui)$  pour obtenir un \'{e}chantillon de loi $P_a(a,b)$ et nous ferons cela pour les n valeurs obtenues sur [0,1].
\\
$$ U = 1 - b^a/ F^{-1}(U)^a$$
$$ \Longrightarrow -F^{-1}(U)^a = -b^a/ U-1$$
$$ \Longrightarrow F^{-1}(U)^a = b^a/ 1-U$$
$$  \Longrightarrow-F^{-1}(U) = b/ (1-U)^{(1/a)}$$
\\
Nous pouvons repr\'{e}senter cette m\'{e}thode sous forme d'un graphique : en mettant en ordonn\'{e}e les n valeurs de la loi Ui et en abscisse la projection pour chacune de ses valeurs de son image inverse ($F^{-1}(Ui)$ ).
\\

\item
 En suivant la m\'{e}thode d\'{e}crite pr\'{e}cedemment, nous  avons simuler m \'{e}chantillon de taille n avec diff\'{e}rentes valeurs pour m,n et a. 
\\
Nous avons ensuite, pour chaque \'{e}chantillon de taille n, calculer l'intervalle de confiance bilat\'{e}ral. Pour cela nous avons utiliser L'intervalle de confiance trouv\'{e} en premi\`{e}re partie qui s'utilise avec $Y=\ln { \frac{X}{2}}$.  A chaque fois que a est bien contenu dans cet intervalle, nous inc\'{e}mentons une variable compteur. La proportion Pr d'IC contenant a est donc $Pr = Compteur/m$.
\\

\begin{figure}[H]
\label{graph1}
\centering
\includegraphics[width=1.0\textwidth]{figures/Graph_P2Q2.pdf}
\caption{Graphe des proportions d'IC($\alpha$) contenant la valeur exacte de a pour diff\'{e}rentes valeurs de $\alpha$}
\end{figure}

Afin que cela soit plus repr\'{e}sentatif,nous avons trac\'{e} un graphique avec les diff\'{e}rentes proportions obtenues en fonction des $\alpha$. (Voir figure 10)
\\

Nous pouvons voir qu'il existe une lin\'{e}arit\'{e} entre la proportion et les $\alpha$. Plus on augmente le nombre d'\'{e}chantillon m et leur taille n et plus l'approximation est exacte. Ces points ont \'{e}t\'{e} obtenus pour les valeurs de $m = 100$, $n = 10, 30, 50, 100, 200, 500$, $a = 3, 5, 10, 20, 50$ et $\alpha = 0.01, 0.05, 0.10, 0.20 ..., 0.80, 0.90, 0.95, 0.99$.
\\
Quand on simule un grand nombre m d\'{e}chantillons de taille $n$ de la  loi $P_a(a,2)$ alors la proportion d'IC($\alpha$) contenant $a$ est aproximativement \'{e}gale \`{a}  $1 - \alpha$.
\\

\item

 Afin d'estimer le param\`{e}tre $a$, nous disposons de trois m\'{e}thodes : la m\'{e}thode des moments, la m\'{e}thode du maximum de vraisemblance qui nous m\`{e}nent au m\^{e}me r\'{e}sultat pour l'\'{e}stimation du param\`{e}tre $a$ et nous pouvons aussi d\'{e}terminer l'estimateur sans bais de variance minimale si celui-ci existe.
\\

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q31.pdf}
\caption{Histogramme des EMV et ESBVM pour $m=100, n=5, a=10$}
\label{graphe2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q32.pdf}
\caption{Histogramme des EMV et ESBVM pour $m=100, n=20,   a=10$}
\label{graph3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q33.pdf}
\caption{Histogramme des EMV et ESBVM pour $m=100, n=50, a=10$}
\label{graphe4}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q34.pdf}
\caption{Histogramme des EMV et ESBVM pour $m=100, n=100, a=10$}
\label{graphe5}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q35.pdf}
\caption{Histogramme des EMV et ESBVM pour $m=500, n=5, a=10$}
\label{graphe6}
\end{figure}

Pour chaque \'{e}chantillons (m en tout) nous avons mis au point sur R une fonction qui calcule les estimateurs propos\'{e}s , qui estime le biais et l'erreur quadratique de chaque estimateur, et qui fait une moyenne pour chacun de ces r\'{e}sultats. Par ces r\'{e}sultats, nous pouvons tracer un histogramme des estimateurs obtenus avec en rouge : la moyenne de ces estimateurs et en bleu : la valeur exacte de a pour laquelle il faut \^{e}tre la plus proche (voir figures 11 à 15)  .
\\

Pour chaque graphique voici les moyennes des biais et des EQM obtenus pour chaque estimateur:
\\
\begin{center}

\begin{tabular}{ *{5}{c|} }
   n & $\bar{biais} EMV$ & $\bar{biais} ESBVM$ &  $\bar{EQM} EMV$ & $\bar{EQM} ESBVM $\\
   5 & 1.691318 & -0.6469459 & 38.3953  &  23.16078  \\
   20 & 0.7355605  & 0.1987825  &   6.691049  & 5.589889\\
   50 & 0.08228447  & -0.1193612  &  1.867297 &  1.801097  \\
   100 & 0.1657237  & 0.06406643 & 0.8215394 & 0.7823774   \\
   500 & 0.02238977  & 0.002344989 & 0.207069  & 0.2057478   \\
 \end{tabular}
\end{center}
~~\\Apr\`{e}s analyse des r\'{e}sultats et des graphiques, nous pouvons en d\'{e}duire que le meilleur estimateur est l'$ESBVM$ car il poss\`{e}de  le biais et l'erreur quadratique moyen le plus faible sur l'ensemble des \'{e}chantillons. Il faut noter que plus la taille des \'{e}chantillons est \'{e}lev\'{e}e, plus les estimateurs sont pr\'{e}cis. Nous pouvons tout de m\^{e}me constater que quelque soit le taille de l'\'{e}chantillon, l'$ESBVM$ est le meilleur estimateur.
\\
\item
Dans cette partie nous simulons \`{a} nouveau m \'{e}chantillons de taille n suivant la loi $P_a(a,2)$ . Nous calculons la moyenne empirique \`{a}  l'aide de la fonction $mean$ disponible sur R et nous calculons son Esperance. Pour chaque valeur n allant de 5 \`{a}  500 nous calculons la difference absolue de ces deux param\`{e}tres. Nous avons ensuite enregistrer le nombre de fois o\`{u} la valeur d\'{e}passe une valeur $\epsilon (Ici, \epsilon = 1 )$. Sur la figure qui suit, nous pouvons remarquer que plus la taille de  l'\'{e}chantillon grandit, moins la diff\'{e}rence entre la moyenne et l'esperance de cet \'{e}chantillon est grande.

\begin{figure}[H]
\label{graphe2}
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q4.pdf}
\caption{Variation de la diff\'{e}rence absolue entre Moyenne est Esperance en fonction de n }
\end{figure}


Par cons\'{e}quent, plus n est grand, moins la moyenne empirique $\bar X_n$  s'\'{e}loigne de l'Esperance $E(X)$ d'au moins $\epsilon$.
On a donc $$\forall\varepsilon>0,\quad \lim_{n \to +\infty} \mathbb{P}\left(\left|\frac{X_1+X_2+\cdots+X_n}{n} -E(X)\right| \geqslant \varepsilon\right) = 0 $$

Autrement dit, $(X_n)$ converge en probabilit\'{e} vers $E(X)$. La moyenne empirique est bien un estimateur convergent de l'\'{e}sperance.
\\

\item


Apr\`{e}s avoir simuler m \'{e}chantillons de taille n suivant la loi $P_a(a,2)$, nous calculons leur moyenne. Nous obtenons donc un \'{e}chantillon de $m$  moyennes empiriques. Pour diff\'{e}rentes valeurs de n (Voir figures), nous avons trac\'{e} un histogramme et un graphe de probabilit\'{e}s pour la loi normale  \`{a} l'aide de la function R $qqnorm$ qui permet de comparer graphiquement la distribution de l'\'{e}chantillon des m moyennes empiriques avec une distribution normale.
\\
\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q51.pdf}
\caption{Etude de la distribution $\bar X_n$ par une distribution normale pour n=5}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q52.pdf}
\caption{Etude de la distribution $ \bar X_n$ par une distribution normale pour n=20}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q54.pdf}
\caption{Etude de la distribution $\ bar X_n$ par une distribution normale pour n=100}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q53.pdf}
\caption{Etude de la distribution $\bar X_n$ par une distribution normale pour n=1000}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q55.pdf}
\caption{Etude de la distribution $\bar X_n$ par une distribution normale pour n=10000}
\end{figure}

Nous pouvons constater que pour $n=5$ il est difficile de dire que la loi normale est un mod\`{e}le approri\'{e} car la courbe a une allure logarithmique. Cependant, plus n augmente et plus les point sont align\'{e}s.  De plus nous pouvons remarquer plus n augmente et plus l'histogramme tend \`{a} avoir une allure de la densit\'{e} $ N(0,1) $
\\ 
Nous pouvons donc en d\'{e}duire que $$\forall n\geq 1, \sqrt{n} \frac{\overline{X_{n}}-E[X]}{\sigma[X]}\underset{L}{\longrightarrow} N(0,1)$$ est v\'{e}rifi\'{e} exp\'{e}rimentalement.
\\

\item
Fixons pour cette partie a=0.5.
\\
Pour \'{e}tudier la convergence en loi des estimateurs, nous \'{e}tudions la fonctions de r\'{e}partition empirique. Nous v\'{e}rifions exp\'{e}rimentalement que plus n est grand, plus la fonction de r\'{e}partition emprique obtenue a une allure de la fonction de r\'{e}partition $ 1 - (2/t)^a$ qui suit la loi $P(a,2)$
\\
\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q61.pdf}
\caption{Fonction de r\'{e}partition $ F(X) = 1 - (2/t)^a$}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/GraphP2Q62.pdf}
\caption{Fonctions de  r\'{e}partition avec $n=5, 20, 100, 1000, 10000$ }
\end{figure}

Ci dessus vous pouvez voir en premier la fonction de r\'{e}partition puis les fonctions de r\'{e}partitions empiriques pour diff\'{e}rentes valeurs de n. Nous avons donc bien $$\forall x \lim_{n \to +\infty} F_n(x) = F(x) $$



\end{enumerate}

% fin du document
%=============
\end{document}
%=============

